# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bq7qpnpqH9cqC-GjwqcXReZ6CuTtOni0
"""

!pip install -qU langchain langchain-groq langchain-community sentence-transformers faiss-cpu pypdf PyMuPDF

import os
from google.colab import files
from IPython.display import Image, display
import fitz  # PyMuPDF

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_groq import ChatGroq
from langchain.chains import RetrievalQA

print("üìÇ Upload your PDF file (only one):")
uploaded = files.upload()
pdf_path = next(iter(uploaded.keys()))
print(f"‚úÖ PDF uploaded: {pdf_path}")

loader = PyPDFLoader(pdf_path)
documents = loader.load()

# Split text into chunks while preserving original page metadata
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = []

for doc in documents:
    sub_docs = text_splitter.split_documents([doc])
    for sub_doc in sub_docs:
        sub_doc.metadata['page'] = doc.metadata['page']
        chunks.append(sub_doc)

print(f"Number of PDF pages: {len(documents)}")
print(f"Number of chunks: {len(chunks)}")

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = FAISS.from_documents(chunks, embeddings)
retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

print("‚úÖ Vectorstore and retriever ready")

# Groq API key setup
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    GROQ_API_KEY = input("Enter your GROQ_API_KEY: ").strip()
    os.environ["GROQ_API_KEY"] = GROQ_API_KEY

# Initialize Groq LLM
llm = ChatGroq(api_key=GROQ_API_KEY, model="llama-3.1-8b-instant")

# Create RetrievalQA chain
rag_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)

print("‚úÖ Retrieval chain ready")

def display_page_image(pdf_path, page_number):
    """Render and display a specific PDF page inline."""
    try:
        doc = fitz.open(pdf_path)
        page = doc.load_page(page_number - 1)  # 0-based index
        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x zoom
        image_path = f"page_{page_number}.png"
        pix.save(image_path)
        display(Image(filename=image_path))
        print(f"üñºÔ∏è Displaying Page {page_number}")
    except Exception as e:
        print(f"‚ùå Error displaying page: {e}")

# Ask any question interactively
query = input("üìù Enter your question: ")

# Run RAG retrieval
response = rag_chain.invoke({"query": query})

# Display answer
print("\n=== ANSWER ===\n")
print(response["result"])

# Display top source snippet
top_doc = response["source_documents"][0]
page_num = top_doc.metadata.get("page", 1)
print(f"\nTop Source Snippet (Page {page_num}):")
print(top_doc.page_content[:300], "...")  # first 300 chars

# Display PDF page image
display_page_image(pdf_path, page_num)